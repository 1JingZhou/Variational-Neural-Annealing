{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "0Hk69E8AiERB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### seeding for reproducibility purposes"
      ],
      "metadata": {
        "id": "3rS85kSfiLt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 100\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heESTiJ5iIZ0",
        "outputId": "40a4f0fc-29d1-4719-b0d4-6b9947eed333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c7d2b02ef90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### helper functions"
      ],
      "metadata": {
        "id": "xGUTCuugiRSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Ising_diag_H(Jz, samples):\n",
        "    \"\"\"samples: (numsamples, N)\n",
        "       Jz: N-1\n",
        "\n",
        "       input spin: 0 or 1 ~ correspond to physics: -1 or 1\n",
        "    \"\"\"\n",
        "    numsamples = samples.shape[0]\n",
        "    N = samples.shape[1]\n",
        "    energy = torch.zeros(numsamples)\n",
        "\n",
        "    for i in range(N-1):\n",
        "        values = samples[:,i] + samples[:, i+1]\n",
        "        valuesN = torch.clone(values)\n",
        "        valuesN[(values == 2) + (values == 0)] = 1\n",
        "        valuesN[values == 1] = -1\n",
        "\n",
        "        energy += valuesN*(-Jz[i])\n",
        "\n",
        "    return energy\n",
        "\n",
        "def Ising_local_E(Jz, Bx, samples, f_probs):\n",
        "    \"\"\"Randomly choose some states (not required to select all)\n",
        "       samples: (numsamples, N)\n",
        "       Jz: N-1\n",
        "       Bx: magnetic field\n",
        "       f_probs: functions to calculate the probabilities\n",
        "\n",
        "       input spin: 0 or 1 ~ correspond to physics: -1 or 1\n",
        "    \"\"\"\n",
        "    numsamples = samples.shape[0]\n",
        "    N = samples.shape[1]\n",
        "\n",
        "    local_energy = torch.zeros(numsamples)\n",
        "    queue_samples = torch.zeros([N+1, numsamples, N])\n",
        "\n",
        "    # diagonal elements (interaction)\n",
        "    for i in range(N-1):\n",
        "        values = samples[:,i] + samples[:, i+1]\n",
        "        valuesN = torch.clone(values)\n",
        "        valuesN[(values == 2) + (values == 0)] = 1\n",
        "        valuesN[values == 1] = -1\n",
        "\n",
        "        local_energy += valuesN*(-Jz[i])\n",
        "\n",
        "    queue_samples[0] = samples\n",
        "\n",
        "    if Bx != 0:\n",
        "        for i in range(N):\n",
        "            valuesN = torch.clone(samples)\n",
        "            valuesN[:,i][samples[:,i] == 1] = 0\n",
        "            valuesN[:,i][samples[:,i] == 0] = 1\n",
        "\n",
        "            queue_samples[i+1] = valuesN\n",
        "\n",
        "        # Process in segments\n",
        "        len_sigmas = (N+1)*numsamples\n",
        "        probs = torch.zeros((N+1)*numsamples)\n",
        "        steps = len_sigmas//50000 + 1\n",
        "\n",
        "        queue_samples = queue_samples.reshape((N+1)*numsamples, N)\n",
        "\n",
        "        for i in range(steps):\n",
        "            if i < steps - 1:\n",
        "                cut = slice((i*len_sigmas)//steps, ((i+1)*len_sigmas)//steps)\n",
        "            else:\n",
        "                cut = slice((i*len_sigmas)//steps, len_sigmas)\n",
        "\n",
        "            probs[cut] = f_probs(queue_samples[cut])\n",
        "\n",
        "        probs_reshape = probs.reshape([N+1, numsamples])\n",
        "\n",
        "        for j in range(numsamples):\n",
        "            local_energy[j] += -Bx*torch.sum(torch.sqrt(probs_reshape[1:,j] / probs_reshape[0,j]))\n",
        "\n",
        "    return local_energy"
      ],
      "metadata": {
        "id": "8GgfRpwFiWTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN (sample & probabilities)"
      ],
      "metadata": {
        "id": "4NoEAoLyibH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiRNN(torch.nn.Module):\n",
        "    def __init__(self, hildim, hidden_size, num_layers):\n",
        "        \"\"\"hildim: hilbert space dimension\n",
        "        \"\"\"\n",
        "        super(MultiRNN, self).__init__()\n",
        "\n",
        "        unit = [hildim] + [hidden_size]*(num_layers-1)\n",
        "\n",
        "        self.cells = torch.nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            self.cells.append(torch.nn.RNN(input_size=unit[i], hidden_size=hidden_size, num_layers=1,dtype=torch.float32))\n",
        "\n",
        "    def forward(self, input, states):\n",
        "        new_states = []\n",
        "        for i, cell in enumerate(self.cells):\n",
        "            input, new_state = cell(input, states[i])\n",
        "            new_states.append(new_state)\n",
        "\n",
        "        return input, new_states\n",
        "\n",
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, num_spins, hildim, hidden_size, num_layers):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.rnn = torch.nn.ModuleList()\n",
        "        self.dense = torch.nn.ModuleList()\n",
        "        for _ in range(num_spins):\n",
        "            self.rnn.append(MultiRNN(hildim, hidden_size, num_layers))\n",
        "            self.dense.append(torch.nn.Sequential(torch.nn.Linear(hidden_size, 2), torch.nn.Softmax(dim=-1)))\n",
        "\n",
        "        self.N = num_spins\n",
        "        self.hildim = hildim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def sample(self, numsamples):\n",
        "        samples = []\n",
        "        probs = []\n",
        "\n",
        "        # initial input (data & hidden layer)\n",
        "        inputs = torch.zeros([numsamples, self.hildim], dtype=torch.float32)\n",
        "        rnn_state = torch.zeros([num_layers, 1, self.hidden_size], dtype=torch.float32)\n",
        "\n",
        "        for i in range(self.N):\n",
        "            rnn_output, rnn_state = self.rnn[i](inputs, rnn_state)\n",
        "            output = self.dense[i](rnn_output)\n",
        "            sample_temp = torch.multinomial(output, 1).reshape(-1)\n",
        "            probs.append(output)\n",
        "            samples.append(sample_temp)\n",
        "            inputs = F.one_hot(sample_temp.type(torch.int64), num_classes = self.hildim).float()\n",
        "\n",
        "        samples = torch.stack(samples, axis=1)\n",
        "\n",
        "        probs = torch.permute(torch.stack(probs, axis=2), (0,2,1))\n",
        "        one_hot_samples = F.one_hot(samples.type(torch.int64), num_classes = self.hildim)\n",
        "        probs_final = (probs * one_hot_samples).sum(dim=2).prod(dim=1)\n",
        "\n",
        "        return samples, probs_final\n",
        "\n",
        "    def probability(self, samples):\n",
        "        numsamples=samples.shape[0]\n",
        "\n",
        "        inputs = torch.zeros([numsamples, self.hildim], dtype=torch.float32)\n",
        "        rnn_state = torch.zeros([self.num_layers, 1, self.hidden_size], dtype=torch.float32)\n",
        "\n",
        "        probs = []\n",
        "        for i in range(self.N):\n",
        "            rnn_output, rnn_state = self.rnn[i](inputs, rnn_state)\n",
        "            output = self.dense[i](rnn_output)\n",
        "            probs.append(output)\n",
        "            inputs = F.one_hot(samples[:,i].type(torch.int64), num_classes = self.hildim).reshape(numsamples, self.hildim).float()\n",
        "\n",
        "        probs = torch.permute(torch.stack(probs, axis=2), (0,2,1))\n",
        "        one_hot_samples = F.one_hot(samples.type(torch.int64), num_classes = self.hildim)\n",
        "        probs_final = (probs * one_hot_samples).sum(dim=2).prod(dim=1)\n",
        "\n",
        "        return probs_final"
      ],
      "metadata": {
        "id": "Nz3x1BUbigt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local free energy and cost function\n"
      ],
      "metadata": {
        "id": "WR2vksqgilNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Floc_and_cost(Eloc, T, probs):\n",
        "    logprobs = torch.log(probs)\n",
        "    Floc = Eloc + T*logprobs\n",
        "    cost = torch.mean(torch.mul(logprobs,Floc.detach())) - torch.mean(logprobs) * torch.mean(Floc.detach())\n",
        "    return Floc, cost"
      ],
      "metadata": {
        "id": "a9TZAm_Uiqft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### system setting"
      ],
      "metadata": {
        "id": "DVph_ouaitMZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqui9G6whgyt"
      },
      "outputs": [],
      "source": [
        "N = 100 # number of spins in Ising chain\n",
        "numsamples = 50 # batch size\n",
        "lr = 1e-3 # learning rate\n",
        "T0 = 2 # Initial temperature\n",
        "Bx0 = 0 # Initial magnetic field\n",
        "\n",
        "hildim = 2\n",
        "hidden_size=64\n",
        "num_layers=3\n",
        "\n",
        "num_warmup_steps = 50 # number of warmup steps\n",
        "num_annealing_steps = 100 # number of annealing steps\n",
        "num_equilbrium_steps = 5 # number of training steps after each annealing step\n",
        "num_steps = num_annealing_steps*num_equilbrium_steps + num_warmup_steps # total gradient steps\n",
        "\n",
        "random_integers = torch.randint(0,2,(N-1,))\n",
        "Jz = 2 * random_integers - 1\n",
        "\n",
        "# Initialize the RNN\n",
        "model = RNN(N, hildim, hidden_size, num_layers)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Variational Annealing"
      ],
      "metadata": {
        "id": "h1x7fmFRi2_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meanEnergy = []\n",
        "varEnergy = []\n",
        "varFreeE = []\n",
        "meanFreeE = []\n",
        "costList = []\n",
        "# samples = torch.ones([numsamples, N])\n",
        "\n",
        "T = T0 # initializing temperature\n",
        "Bx = Bx0 # initializing magnetic field\n",
        "\n",
        "for i in range(num_steps):\n",
        "    # Annealing\n",
        "    if i+1 >= num_warmup_steps and (i -num_warmup_steps) % num_equilbrium_steps == 0:\n",
        "        annealing_step = (i-num_warmup_steps)/num_equilbrium_steps\n",
        "        T = T0*(1 - annealing_step/num_annealing_steps)\n",
        "        Bx = Bx0*(1-annealing_step/num_annealing_steps)\n",
        "\n",
        "        # current status after the annealing\n",
        "        print(\"\\nAnnealing step: {0}/{1}\".format(annealing_step, num_annealing_steps))\n",
        "\n",
        "    # get samples and probabilities from the RNN\n",
        "    samples, probabilities = model.sample(numsamples)\n",
        "\n",
        "    # local energies\n",
        "    local_energies = Ising_local_E(Jz, Bx, samples, model.probability)\n",
        "\n",
        "    # expectation and variance of H\n",
        "    meanE = torch.mean(local_energies)\n",
        "    varE = torch.var(local_energies)\n",
        "    meanEnergy.append(meanE)\n",
        "    varEnergy.append(varE)\n",
        "\n",
        "    # Free energy and cost\n",
        "    Floc, cost = Floc_and_cost(local_energies, T, probabilities)\n",
        "\n",
        "    # expectation and variance of F\n",
        "    meanF = torch.mean(Floc)\n",
        "    varF = torch.var(Floc)\n",
        "    meanFreeE.append(meanF)\n",
        "    varFreeE.append(varF)\n",
        "\n",
        "    costList.append(cost.item())\n",
        "\n",
        "    # print process\n",
        "    if (i-num_warmup_steps) % num_equilbrium_steps == 0:\n",
        "        print('mean(E):{0}, mean(F):{1}, var(E):{2}, var(F): {3}, #samples {4}, #Training step {5}'.format(meanE,meanF,varE,varF,numsamples, i+1))\n",
        "        print('Temperature:', T)\n",
        "        print('Magnetic field:', Bx)\n",
        "        print('cost:', cost.item())\n",
        "        print('min:',torch.min(local_energies).item())\n",
        "\n",
        "    # end of the annealing\n",
        "    if i + 1 == num_steps:\n",
        "        numsamples_final = 10**5 #Number of samples at the end\n",
        "        Nsteps = 20 # deal with the samples in segments\n",
        "        numsamples_each = numsamples_final//Nsteps\n",
        "\n",
        "        energies_final = torch.zeros(numsamples_final)\n",
        "        solutions = torch.zeros([numsamples_final, N])\n",
        "        print(\"\\nEnd of the annealing\")\n",
        "\n",
        "        for i in range(Nsteps):\n",
        "            samples_final, probs_final = model.sample(numsamples_each)\n",
        "            energies_final[i*numsamples_each: (i+1)*numsamples_each] = Ising_diag_H(Jz, samples_final)\n",
        "            solutions[i*numsamples_each: (i+1)*numsamples_each] = samples_final\n",
        "\n",
        "        print(\"meanE = \", torch.mean(energies_final))\n",
        "        print(\"varE = \", torch.var(energies_final))\n",
        "        print(\"minE = \", torch.min(energies_final))\n",
        "\n",
        "    # gradient descent\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-e9dpjuki3bY",
        "outputId": "9cfa4281-2e12-4fdb-a72a-e1ef175519b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean(E):0.6000000238418579, mean(F):-137.1930389404297, var(E):85.2244873046875, var(F): 84.64690399169922, #samples 50, #Training step 1\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: 0.375\n",
            "min: -21.0\n",
            "mean(E):-0.9200000166893005, mean(F):-134.93359375, var(E):98.605712890625, var(F): 115.74833679199219, #samples 50, #Training step 6\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: 6.970703125\n",
            "min: -29.0\n",
            "mean(E):-7.199999809265137, mean(F):-139.6746826171875, var(E):131.14285278320312, var(F): 118.32892608642578, #samples 50, #Training step 11\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: 3.6162109375\n",
            "min: -29.0\n",
            "mean(E):-3.799999952316284, mean(F):-136.57554626464844, var(E):84.40816497802734, var(F): 80.83570098876953, #samples 50, #Training step 16\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: 4.5732421875\n",
            "min: -23.0\n",
            "mean(E):-7.159999847412109, mean(F):-140.18051147460938, var(E):78.66775512695312, var(F): 89.54158782958984, #samples 50, #Training step 21\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: 9.0791015625\n",
            "min: -27.0\n",
            "mean(E):-6.599999904632568, mean(F):-141.18133544921875, var(E):102.53060913085938, var(F): 82.73036193847656, #samples 50, #Training step 26\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: -0.263671875\n",
            "min: -27.0\n",
            "mean(E):-8.239999771118164, mean(F):-143.31539916992188, var(E):102.02285766601562, var(F): 72.18649291992188, #samples 50, #Training step 31\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: -2.8134765625\n",
            "min: -29.0\n",
            "mean(E):-9.760000228881836, mean(F):-143.28053283691406, var(E):97.94122314453125, var(F): 59.67097854614258, #samples 50, #Training step 36\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: -3.439453125\n",
            "min: -41.0\n",
            "mean(E):-12.880000114440918, mean(F):-146.25787353515625, var(E):64.72000122070312, var(F): 50.130123138427734, #samples 50, #Training step 41\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: 0.0478515625\n",
            "min: -27.0\n",
            "mean(E):-11.199999809265137, mean(F):-142.40170288085938, var(E):81.34693908691406, var(F): 67.37895202636719, #samples 50, #Training step 46\n",
            "Temperature: 2\n",
            "Magnetic field: 0\n",
            "cost: 3.09375\n",
            "min: -31.0\n",
            "\n",
            "Annealing step: 0.0/100\n",
            "mean(E):-12.239999771118164, mean(F):-143.91860961914062, var(E):64.63510131835938, var(F): 44.718040466308594, #samples 50, #Training step 51\n",
            "Temperature: 2.0\n",
            "Magnetic field: 0.0\n",
            "cost: 0.4345703125\n",
            "min: -31.0\n",
            "\n",
            "Annealing step: 1.0/100\n",
            "mean(E):-13.760000228881836, mean(F):-144.22900390625, var(E):117.36979675292969, var(F): 74.11007690429688, #samples 50, #Training step 56\n",
            "Temperature: 1.98\n",
            "Magnetic field: 0.0\n",
            "cost: -5.57421875\n",
            "min: -35.0\n",
            "\n",
            "Annealing step: 2.0/100\n",
            "mean(E):-16.799999237060547, mean(F):-144.92530822753906, var(E):104.36734771728516, var(F): 57.852821350097656, #samples 50, #Training step 61\n",
            "Temperature: 1.96\n",
            "Magnetic field: 0.0\n",
            "cost: -5.0771484375\n",
            "min: -39.0\n",
            "\n",
            "Annealing step: 3.0/100\n",
            "mean(E):-20.520000457763672, mean(F):-146.46913146972656, var(E):108.49959564208984, var(F): 54.87300491333008, #samples 50, #Training step 66\n",
            "Temperature: 1.94\n",
            "Magnetic field: 0.0\n",
            "cost: -5.814453125\n",
            "min: -45.0\n",
            "\n",
            "Annealing step: 4.0/100\n",
            "mean(E):-18.84000015258789, mean(F):-144.8908233642578, var(E):119.64734649658203, var(F): 54.82954788208008, #samples 50, #Training step 71\n",
            "Temperature: 1.92\n",
            "Magnetic field: 0.0\n",
            "cost: -8.3388671875\n",
            "min: -41.0\n",
            "\n",
            "Annealing step: 5.0/100\n",
            "mean(E):-23.68000030517578, mean(F):-146.3948211669922, var(E):72.4261245727539, var(F): 28.831993103027344, #samples 50, #Training step 76\n",
            "Temperature: 1.9\n",
            "Magnetic field: 0.0\n",
            "cost: -3.6396484375\n",
            "min: -39.0\n",
            "\n",
            "Annealing step: 6.0/100\n",
            "mean(E):-24.31999969482422, mean(F):-144.4132080078125, var(E):72.9159164428711, var(F): 39.67509078979492, #samples 50, #Training step 81\n",
            "Temperature: 1.88\n",
            "Magnetic field: 0.0\n",
            "cost: -0.3671875\n",
            "min: -43.0\n",
            "\n",
            "Annealing step: 7.0/100\n",
            "mean(E):-26.920000076293945, mean(F):-143.79977416992188, var(E):76.56489562988281, var(F): 44.831974029541016, #samples 50, #Training step 86\n",
            "Temperature: 1.8599999999999999\n",
            "Magnetic field: 0.0\n",
            "cost: -2.0537109375\n",
            "min: -45.0\n",
            "\n",
            "Annealing step: 8.0/100\n",
            "mean(E):-31.920000076293945, mean(F):-145.7543487548828, var(E):63.05469512939453, var(F): 23.1494197845459, #samples 50, #Training step 91\n",
            "Temperature: 1.84\n",
            "Magnetic field: 0.0\n",
            "cost: -1.662109375\n",
            "min: -49.0\n",
            "\n",
            "Annealing step: 9.0/100\n",
            "mean(E):-32.31999969482422, mean(F):-144.50466918945312, var(E):98.05877685546875, var(F): 37.319862365722656, #samples 50, #Training step 96\n",
            "Temperature: 1.82\n",
            "Magnetic field: 0.0\n",
            "cost: -3.564453125\n",
            "min: -59.0\n",
            "\n",
            "Annealing step: 10.0/100\n",
            "mean(E):-35.279998779296875, mean(F):-144.61471557617188, var(E):103.34857177734375, var(F): 32.92412567138672, #samples 50, #Training step 101\n",
            "Temperature: 1.8\n",
            "Magnetic field: 0.0\n",
            "cost: -8.0166015625\n",
            "min: -57.0\n",
            "\n",
            "Annealing step: 11.0/100\n",
            "mean(E):-39.400001525878906, mean(F):-145.06292724609375, var(E):64.32653045654297, var(F): 19.06523895263672, #samples 50, #Training step 106\n",
            "Temperature: 1.78\n",
            "Magnetic field: 0.0\n",
            "cost: -1.9033203125\n",
            "min: -55.0\n",
            "\n",
            "Annealing step: 12.0/100\n",
            "mean(E):-41.08000183105469, mean(F):-144.7888641357422, var(E):75.91183471679688, var(F): 9.613934516906738, #samples 50, #Training step 111\n",
            "Temperature: 1.76\n",
            "Magnetic field: 0.0\n",
            "cost: -3.9853515625\n",
            "min: -67.0\n",
            "\n",
            "Annealing step: 13.0/100\n",
            "mean(E):-41.63999938964844, mean(F):-143.40882873535156, var(E):68.96979522705078, var(F): 13.763188362121582, #samples 50, #Training step 116\n",
            "Temperature: 1.74\n",
            "Magnetic field: 0.0\n",
            "cost: -1.9306640625\n",
            "min: -59.0\n",
            "\n",
            "Annealing step: 14.0/100\n",
            "mean(E):-42.84000015258789, mean(F):-143.54441833496094, var(E):89.93305969238281, var(F): 7.42800760269165, #samples 50, #Training step 121\n",
            "Temperature: 1.72\n",
            "Magnetic field: 0.0\n",
            "cost: -2.767578125\n",
            "min: -65.0\n",
            "\n",
            "Annealing step: 15.0/100\n",
            "mean(E):-43.560001373291016, mean(F):-141.88609313964844, var(E):105.1493911743164, var(F): 8.613813400268555, #samples 50, #Training step 126\n",
            "Temperature: 1.7\n",
            "Magnetic field: 0.0\n",
            "cost: -5.900390625\n",
            "min: -63.0\n",
            "\n",
            "Annealing step: 16.0/100\n",
            "mean(E):-47.400001525878906, mean(F):-142.6944580078125, var(E):97.30612182617188, var(F): 9.4201021194458, #samples 50, #Training step 131\n",
            "Temperature: 1.68\n",
            "Magnetic field: 0.0\n",
            "cost: -0.66064453125\n",
            "min: -75.0\n",
            "\n",
            "Annealing step: 17.0/100\n",
            "mean(E):-48.720001220703125, mean(F):-141.0154266357422, var(E):65.63428497314453, var(F): 5.434070587158203, #samples 50, #Training step 136\n",
            "Temperature: 1.66\n",
            "Magnetic field: 0.0\n",
            "cost: -0.08740234375\n",
            "min: -63.0\n",
            "\n",
            "Annealing step: 18.0/100\n",
            "mean(E):-49.91999816894531, mean(F):-140.70965576171875, var(E):64.3608169555664, var(F): 6.070498943328857, #samples 50, #Training step 141\n",
            "Temperature: 1.6400000000000001\n",
            "Magnetic field: 0.0\n",
            "cost: -1.625\n",
            "min: -67.0\n",
            "\n",
            "Annealing step: 19.0/100\n",
            "mean(E):-50.400001525878906, mean(F):-139.51812744140625, var(E):64.2040786743164, var(F): 6.751285076141357, #samples 50, #Training step 146\n",
            "Temperature: 1.62\n",
            "Magnetic field: 0.0\n",
            "cost: -0.169921875\n",
            "min: -71.0\n",
            "\n",
            "Annealing step: 20.0/100\n",
            "mean(E):-49.560001373291016, mean(F):-138.82147216796875, var(E):59.43510055541992, var(F): 3.4944894313812256, #samples 50, #Training step 151\n",
            "Temperature: 1.6\n",
            "Magnetic field: 0.0\n",
            "cost: -1.9765625\n",
            "min: -65.0\n",
            "\n",
            "Annealing step: 21.0/100\n",
            "mean(E):-53.959999084472656, mean(F):-137.78225708007812, var(E):77.91673278808594, var(F): 4.264544486999512, #samples 50, #Training step 156\n",
            "Temperature: 1.58\n",
            "Magnetic field: 0.0\n",
            "cost: -3.27490234375\n",
            "min: -69.0\n",
            "\n",
            "Annealing step: 22.0/100\n",
            "mean(E):-51.439998626708984, mean(F):-136.71644592285156, var(E):73.51673126220703, var(F): 2.35821270942688, #samples 50, #Training step 161\n",
            "Temperature: 1.56\n",
            "Magnetic field: 0.0\n",
            "cost: -0.70166015625\n",
            "min: -69.0\n",
            "\n",
            "Annealing step: 23.0/100\n",
            "mean(E):-52.91999816894531, mean(F):-135.54779052734375, var(E):69.05469512939453, var(F): 3.2793023586273193, #samples 50, #Training step 166\n",
            "Temperature: 1.54\n",
            "Magnetic field: 0.0\n",
            "cost: -0.8447265625\n",
            "min: -73.0\n",
            "\n",
            "Annealing step: 24.0/100\n",
            "mean(E):-53.400001525878906, mean(F):-135.05979919433594, var(E):51.75510025024414, var(F): 1.995381236076355, #samples 50, #Training step 171\n",
            "Temperature: 1.52\n",
            "Magnetic field: 0.0\n",
            "cost: -0.82958984375\n",
            "min: -71.0\n",
            "\n",
            "Annealing step: 25.0/100\n",
            "mean(E):-55.959999084472656, mean(F):-133.87774658203125, var(E):101.91673278808594, var(F): 3.4445383548736572, #samples 50, #Training step 176\n",
            "Temperature: 1.5\n",
            "Magnetic field: 0.0\n",
            "cost: -5.2060546875\n",
            "min: -75.0\n",
            "\n",
            "Annealing step: 26.0/100\n",
            "mean(E):-54.79999923706055, mean(F):-133.2633514404297, var(E):62.73469543457031, var(F): 1.9370735883712769, #samples 50, #Training step 181\n",
            "Temperature: 1.48\n",
            "Magnetic field: 0.0\n",
            "cost: -1.57470703125\n",
            "min: -69.0\n",
            "\n",
            "Annealing step: 27.0/100\n",
            "mean(E):-56.119998931884766, mean(F):-132.09226989746094, var(E):64.84244537353516, var(F): 1.309335470199585, #samples 50, #Training step 186\n",
            "Temperature: 1.46\n",
            "Magnetic field: 0.0\n",
            "cost: -1.1923828125\n",
            "min: -71.0\n",
            "\n",
            "Annealing step: 28.0/100\n",
            "mean(E):-56.720001220703125, mean(F):-130.99440002441406, var(E):45.38938903808594, var(F): 1.253300428390503, #samples 50, #Training step 191\n",
            "Temperature: 1.44\n",
            "Magnetic field: 0.0\n",
            "cost: -0.30419921875\n",
            "min: -75.0\n",
            "\n",
            "Annealing step: 29.0/100\n",
            "mean(E):-57.84000015258789, mean(F):-130.1973114013672, var(E):73.15755462646484, var(F): 1.4600679874420166, #samples 50, #Training step 196\n",
            "Temperature: 1.42\n",
            "Magnetic field: 0.0\n",
            "cost: -1.19384765625\n",
            "min: -75.0\n",
            "\n",
            "Annealing step: 30.0/100\n",
            "mean(E):-58.119998931884766, mean(F):-129.20379638671875, var(E):55.862857818603516, var(F): 1.0380396842956543, #samples 50, #Training step 201\n",
            "Temperature: 1.4\n",
            "Magnetic field: 0.0\n",
            "cost: -2.41748046875\n",
            "min: -75.0\n",
            "\n",
            "Annealing step: 31.0/100\n",
            "mean(E):-58.2400016784668, mean(F):-128.41273498535156, var(E):49.777957916259766, var(F): 1.0184122323989868, #samples 50, #Training step 206\n",
            "Temperature: 1.38\n",
            "Magnetic field: 0.0\n",
            "cost: -1.0927734375\n",
            "min: -73.0\n",
            "\n",
            "Annealing step: 32.0/100\n",
            "mean(E):-59.439998626708984, mean(F):-127.24623107910156, var(E):79.394287109375, var(F): 1.3658041954040527, #samples 50, #Training step 211\n",
            "Temperature: 1.3599999999999999\n",
            "Magnetic field: 0.0\n",
            "cost: -2.92041015625\n",
            "min: -73.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-860e880f5422>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# get samples and probabilities from the RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# local energies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f9d47d24ccfb>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, numsamples)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0msample_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f9d47d24ccfb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, states)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mnew_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RNN_TANH\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                 result = _VF.rnn_tanh(\n\u001b[0m\u001b[1;32m    715\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plots"
      ],
      "metadata": {
        "id": "liLTCR1IjF1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cost plot\n",
        "plt.figure()\n",
        "plt.xlabel(\"steps\")\n",
        "plt.ylabel(\"cost\")\n",
        "plt.title(\"COST\")\n",
        "plt.plot(range(1,num_steps+1), costList)\n",
        "plt.show()\n",
        "\n",
        "# epsilon of final test (the end of annealing) 直方图\n",
        "MIN, MAX = 1e-10, 1.0\n",
        "groundE = -(N-1)\n",
        "epsilon = ((energies_final - groundE)/N) # residual energy per site\n",
        "epsilon[epsilon==0.0] = MIN\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.hist(epsilon, alpha=0.9, color='b', bins = 10 ** np.linspace(np.log10(MIN), np.log10(MAX), 20), label='$N_{annealing}='+str(num_annealing_steps)+'$')\n",
        "\n",
        "plt.gca().set_xscale(\"log\")\n",
        "plt.ylim(0, len(energies_final))\n",
        "plt.legend(loc='best', frameon=False)\n",
        "plt.xlabel(r'$\\epsilon_{res}/N$')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PxL9vNGPjF92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}